![image](https://user-images.githubusercontent.com/110235113/185787929-68c33294-68d6-4eb2-9f74-0c7270b4918f.png)



# 1-Proyecto-Pandas-Shark

En este proyecto, realizare una disputa, limpieza y manejo de datos con Pandas.
El proyecto consistira en realizar una disputa, limpieza y manejo de unos datos en una base de datos liosa acerca de ataques de tiburones, las cuales (la base de datos) voy a analizar.

A su vez, hay una lista de cosas por hacer las cuales seran las siguientes:

  1- Explorar los datos y escribir lo que encontró usando: df.describe(), df["columna"], etc.
  
  2- Usando al menos 5 técnicas de limpieza de datos dentro de un archivo llamado clean.ipynb:
  
          - valores nulos, caída de columnas, datos duplicados, manipulación de cadenas, aplicar fn, categorizar, expresiones regulares, etc.
          
Se han realizado estos pasos:

  1- La importación de las distintas bibliotecas que se han utilizado
  
  2- Abrir archivo con el que se va a trabajar
  
  3- Ver que datos hay en el archivo
  
  4- Empezar con la limpieza, los duplicados, los que contienen valor nulo, etc.
  
  5- Quitar toda las lineas duplicadas
  
  6- Empezar a ver en cada columna los valores que posee
  
  7- Agrupar las columnas por cosas similares y quitar los valores nulos
  
  8- Quitar lineas que veamos que no son importantes
  
          
# 1-Project-Pandas-Shark          
          
 In this project, I will perform data wrangling, cleansing, and handling with Pandas.
The project will consist of disputing, cleaning and managing some data in a messy database about shark attacks, which (the database) I am going to analyze.

In turn, there is a list of things to do which will be the following:

  1- Explore the data and write what it found using: df.describe(), df["column"], etc.
  
  2- Using at least 5 data cleaning techniques inside a file called clean.ipynb:
  
          - null values, column dropping, duplicate data, string manipulation, apply fn, categorize, regular expressions, etc.


These steps have been performed:

  1- The import of the different libraries that have been used
  
  2- Open file with which you are going to work
  
  3- See what data is in the file
  
  4- Start with the cleaning, the duplicates, those that contain null value, etc.
  
  5- Remove all duplicate lines
  
  6- Begin to see in each column the values it has
  
  7- Group columns by similar things and remove null values
  
  8- Remove lines that we see that are not important
